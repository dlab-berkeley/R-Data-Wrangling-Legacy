## Challenge 1 

Here is a dataset inspired by an Economist/YouGov Poll about the importance of unemployment in the United States. 

```{r}
challenge_1 <- tibble(
  issue_importance = c("Very Important", "Somewhat Important",
                       "Not very Important", "Unimportant"),
  `18-29` = c(.59, .28, .08, .05),
  `30-44` = c(.66, .27, .06, .02),
  `45-64` = c(.69, .28, .03, .01),
  `65+` = c(.7, .27, .02, .01)
)

head(challenge_1)
```

Answer the following: 

1. How many observations are in the data set?

*16. While they are only 4 rows in this table, there are four categories of issue importance and four age groups. 4x4 = 16 total observations.*

2. How many columns are in the data set?

```{r}
ncol(challenge_1)
```

3. Is every column a variable?

*No! This data is messy. The first column is a variable that contains the universe of issue importance answers. However, the next five columns are all instances of the variable age.*


## Challenge 2

Create a new data frame object called `cats_and_dogs` that filters the `animals` data frame for all observations for which the animal type is a cat or a dog. Use the pipe operator to chain the functions together. 

```{r}
cats_and_dogs <- animals |> 
  filter(Type == "Cat"|Type == "Dog")
```
  
## Challenge 3

Let's put the verbs we've learned so far into action all at once. Answer the question "What are the total number of dog rescues for each borough?" by making a data frame called `borough_dog_rescues` and arranging the rows by borough in alphabetical order. 

```{r}
## Your Code here 
borough_dog_rescues <- animals |> 
  group_by(Borough) |>
  filter(Type == "Dog") |>
  count(Type) |>
  arrange(Borough)

```

## Challenge 4

Create a data frame that considers the average rescue cost, median rescue cost, and standard deviation for bird rescues for each property category year. Save the result of your workflow into a data frame object called `bird_stats`


```{r, include=F}
#YOUR CODE HERE
bird_stats <- animals |> 
  group_by(PropertyCategory, Year) |>
  filter(Type == "Bird") |>
  summarise(median_cost = median(RescueCost, na.rm = T),
            avg_cost = mean(RescueCost, na.rm = T), 
            sd_cost = sd(RescueCost, na.rm = T),
            .groups = "drop_last")

```


## Challenge 5

Add a column to the gapminder dataset that contains the continent's total population of each observation in a given year. For example, if the first observation was Afghanistan in 1952, the new column would contain the population of Asia in 1952. 

```{r}
gapminder_c6 <- gapminder |> 
  group_by(continent, year) |> 
  mutate(continent_pop = sum(pop))
``` 

  
## Challenge 6 

Use dplyr to: (a) add a column called `gdpPercap_diff` that contains the difference between the observation's `gdpPercap` and the mean `gdpPercap` of the continent in that year, (b) arrange the data frame by the column you just created, in descending order (so that the relatively richest country/years are listed first)

```{r}
gapminder_gdpPercap_diff <- gapminder_c6 |>  
  group_by(continent, year) |> 
   mutate(mean_continent_gdp = mean(gdpPercap),
          gdpPercap_diff = gdpPercap - mean_continent_gdp) |> 
  arrange(desc(gdpPercap_diff))
```


## Challenge 7 

The IGS poll also contains a question broken down by region (`cal_region.csv`). Build a pipeline that reads and tidies the data. For extra practice, make a similar graph to display the results. 

```{r}
## Full pipe here 
read_csv(here("data/cal_region.csv"), show_col_types = F) |> 
  pivot_longer(-leaving, 
               names_to = "region", 
               values_to = "percent_agreement") |> 
  ggplot(aes(x = leaving, y = percent_agreement, fill=region))+
  geom_col(position = 'dodge')+
  xlab("Moving Consideration Level")+
  ylab("Percent Agreement")+
  scale_fill_viridis_d()+
  ggtitle("Californians Consideration to Leaving the State by Region")

```

## Challenge 8

Edit the workflow presented above to split on the fifth character. Use `mutate` to replace the incorrect values with corrected and capitalized names.  

```{r}
## Here's a solution that takes advantage of stringr capabilities
## There are multiple ways to solve this problem
birds |> 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE) |>
  separate(sight, c("type", "location"),sep = 5) |>
  mutate(type = str_replace_all(type, "warbl", "warbler")|>str_to_title(),
         location = if_else(str_detect(location, "Ne"), "Nest", "Air"))

### Here's a way using base string function 
birds |> 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE) |>
  separate(sight, c("type", "location"),sep = 5) |>
  mutate(type = if_else(grepl("w", type, ignore.case = TRUE), "Warbler", "Eagle"),
         location = if_else(grepl("Ne", location), "Nest", "Air"))

### Here's another brute force way 
birds |>
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE) |>
  separate(sight, c("type", "location"),sep = 5) |>
  mutate(type = if_else(str_starts(type, "w"), "Warbler", "Eagle"),
         location = case_when(
           str_detect(location, "ir")~"Air",
           str_detect(location, "Ne")~"Nest",
           TRUE ~ location
         ))
```


## Challenge 9: Bulk Recoding Values 

Suppose you have a survey 

```{r}
set.seed(1234)
survey_raw_data <-tibble(
  ID = LETTERS[1:15],
  var1 = sample(1:15, replace = F),
  var2 = sample(16:30, replace = F),
  var3 = sample(31:45, replace = F)
)
glimpse(survey_raw_data)
```

Survey data is likely to contain errors. Perhaps the enumerators filled in a question incorrectly. Maybe you have a special value for missing data. As a subject matter expert, you realize that there are several fixes that need to be made globally. You put them into a data frame. 

```{r}
fixes <- tibble(
  ID = c("O", "G", "D", "D"),
  original_var = c("var1", "var2", "var2", "var3"),
  original_response = as.integer(c(1, 28, 19, 34)),
  correct_response = as.integer(c(1000, 2800, 1900, 3400))
)
glimpse(fixes)
```

Here we have a problem of updating several variables based on a set of potentially different conditions. Each variable needs to be updated based on the ID, but we do not need to update every variable/ID combination. 

Build a workflow that converts the incorrect answers to correct answers. A solution to this problem makes use of `left_join()`, `mutate()`, `select()`, and both `pivot_longer()` and `pivot_wider()`

```{r}
corrected_data <- survey_raw_data |> 
  pivot_longer(cols = -ID,
               names_to = "var_name",
               values_to = "original_value") |>
  left_join(fixes, by = c("ID", "var_name" = "original_var")) |>
  mutate(corrected_value = if_else(is.na(original_response),
                                   original_value,
                                   correct_response)) |>
  select(-original_value, -correct_response, -original_response) |>
  pivot_wider(names_from = "var_name",
              values_from = "corrected_value")
  

```

## Challenge 10: Combining files with readr 

In the data folder, there is a sub-directory called penguins. This directory splits up the data from the `palmerpenguins` package into three data frames split by species. Turn these three files into one data frame. 

```{r}
## Get files
files <- fs::dir_ls(path = here("data/penguins"), glob = "*species_*.csv")

## Combine data frames 
penguins_df <- files |> 
  read_csv(id = "path", show_col_types = FALSE)
```