---
title: "R Data Wrangling and Manipulation: Part 2"
theme: readable
output:
  html_document:
    toc: true
    toc_float: true
    fig_width: 12
    fig_height: 7
---

```{r chunksetup, include=FALSE} 
library(janitor)
library(here)
library(tidyverse)
library(tibble)
```

## The big picture 

Part 2 focuses on extending the base skills learned in Part 1. We are still interested in turning messy data into tidy data. In this section, we will cover several common problems with messy data sets [Wickham 2014](https://vita.had.co.nz/papers/tidy-data.html). These are 

1. Column headers that are values, not variable names. 
2. Overloading variables into a single column. 
3. Storing variables in both rows and columns. 
4. Storing multiple types of units in the same data frame. 
5. Storing a single unit in multiple tables. 

We will dive into additional tools within the tidyverse to make data wrangling easier and more efficient. To that end, we will cover how to use our `dplyr` and `tidyr` functions within functions. In the process, we will gain insight into the tidy eval data-masking framework, how it works, and how to make it work for us. 

We will also see how to apply functions over multiple files with functional programming via the `purrr` package. 

Finally we'll cover two table verbs since it is rare that we will only have one data frame to do all of our analysis. 

## Column headers that are values, not variable names. 

This messy type of data is common in survey data, especially if you're working off of someone else's crosstabs. 

Imagine you're doing research the housing crisis in California. You come across a dataset from Berkeley's [Institute for Governmental Studies](https://igs.berkeley.edu/research/berkeley-igs-poll) that has information on preferences for moving broken down by age group. 

Read in the dataset, which is called `cal_housing.csv` in the data folder. 

```{r, message = F, warning = F}
cal_housing <- read_csv(here("data/cal_housing.csv"))
glimpse(cal_housing)
```

Our end goal is to make a visualization showing consideration of moving by age group. `ggplot2` presumes that we have tidy data to work. In order to make our graph, we need to *pivot* the non-variable columns into a two-column key-value pair. 

Recall from part 1 that the appropriate tidyverse function for this operation is `pivot_longer()`. 

```{r}
cal_housing_long <- cal_housing %>% 
  pivot_longer(-leaving, 
               names_to = "age", 
               values_to = "percent_agreement")
head(cal_housing_long)
```

From here, we could make a bar graph showing response by age groups. 
```{r}
cal_housing_long %>% 
  ggplot(aes(x = leaving, y = percent_agreement, fill=age))+
  geom_col(position = 'dodge')+
  xlab("Moving Consideration Level")+
  ylab("Percent Agreement")+
  scale_fill_discrete(type = "viridis")+
  ggtitle("Californians Consideration to Leaving the State")

```

## Challenge 9 

The IGS poll also contains a question broken down by region (`cal_region.csv`). Build a pipeline that reads and tidies the data. For extra practice, make a similar graph to display the results. 

```{r}
## Fill in your solution here 
```

## Overloading variables into a single column. 

Sometimes we have a dataset where our key column is a combination of multiple variables. To my knowledge, this is a rather common raw data format in research projects that collect data at multiple sub-level sites over time. 

To illustrate the problem, consider the following dataset inspired by bird watchers. 

```{r}
birds <- read_csv(here("data/birds.csv"))
glimpse(birds)
```

We see that we have columns that combine two different variables, the species of bird, and the location of a sighting. When encountering this situation, we use a two step process. 

1. Pivot to gather the non-variable columns 
2. Separate the overloaded column. 

In a workflow, it looks like this 

```{r}
goodBirds <- birds %>% 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE)%>%
  separate(sight, c("type", "location"),sep = "(?=[A-Z])")
glimpse(goodBirds)
```

The workflow above used a [regular expression](https://stringr.tidyverse.org/articles/regular-expressions.html) to split and keep the capital letter. Regular expressions are in general beyond the scope of this course. 



Another way to separate is by position. That call looks like this 

```{r, eval = F}
separate(col = VAR, into = c("VAR1", "VAR2"), sep = NUMBER)
## example that splits on the first character 
separate(col = col, into = c("var1", "var2"), sep = 1)
```

On datasets that have a standard format, separating by position can be useful. Let's look at what happens when we separate by the 1st position 

```{r}
sepEx <- birds %>% 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE)%>%
  separate(sight, c("type", "location"),sep = 1)
glimpse(sepEx)
```

We can fix our incorrect columns with `mutate()`. The following is a brute force method to do this, but as you continue on in your data wrangling journey I strongly encourage you to seek out more efficient ways of solving this problem. 

```{r}
sepExFixed <- sepEx %>% 
  mutate(type = if_else(type == "e", "Eagle", "Warbler"),
         location = case_when(
           location == "agleNest"~"Nest",
           location == "agleAir"~"Air",
           location == "arblerNest"~"Nest",
           location == "arblerAir"~"Air"
         ))
head(sepExFixed)
```


## Challenge 10 

Edit the workflow presented above to split on the fifth character. Use `mutate` to replace the incorrect values with corrected and capitalized names. You can follow the brute force way shown above, or potentially investigate [str_replace_all()](https://stringr.tidyverse.org/reference/str_replace.html), [str_detect()](https://stringr.tidyverse.org/reference/str_detect.html), and [str_to_title()](https://stringr.tidyverse.org/reference/case.html) for options with string matching. 

```{r}


```


## Storing variables in both rows and columns. 

Far less often, though far more frustratingly, variables can be stored in both rows and columns. A common situation for this is data on climate variables. To demonstrate, consider the data on weather in Berkeley. 

TODO DATA HAS TO GO HERE. 


## Challenge 11 

Follow similar steps to build a tidy data set from the `weatherChallenge.csv` dataset. After cleaning the data, group by year and find the average tmax and tmin. 

TODO, GET CHALLENGE DATA 


## Storing multiple types of units in the same data frame. 

A key principle of tidy data, and data wrangling in general, is to keep like for like in the same table. Datasets often violate this guideline when they have values collected at multiple levels on different types of observations. 


## Storing a single unit in multiple tables. 


## Two Table Verbs

### joins 

### Bind_cols/Bind_rows 

#### `bind_cols()` combines variables 

#### `bind_rows()` combines cases 
