---
title: "R Data Wrangling and Manipulation: Part 2"
theme: readable
output:
  html_document:
    toc: true
    toc_float: true
    fig_width: 12
    fig_height: 7
---

```{r chunksetup, include=FALSE} 
library(janitor)
library(here)
library(tidyverse)
library(tibble)
```

## The big picture 

Part 2 focuses on extending the base skills learned in Part 1. We are still interested in turning messy data into tidy data. In this section, we will cover several common problems with messy data sets [Wickham 2014](https://vita.had.co.nz/papers/tidy-data.html). These are 

1. Column headers that are values, not variable names. 
2. Overloading variables into a single column. 
3. Storing variables in both rows and columns. 
4. Storing multiple types of units in the same data frame. 
5. Storing a single unit in multiple tables. 

Within our discussion of (4) and (5) we will cover two table verbs that exist in the tidyverse. In real data analyis projects, it is rare that we will only have one data frame to do all of our analysis. 

## Column headers that are values, not variable names. 

This messy type of data is common in survey data, especially if you're working off of someone else's crosstabs. 

Imagine you're doing research on the housing crisis in California. You come across a dataset from Berkeley's [Institute for Governmental Studies](https://igs.berkeley.edu/research/berkeley-igs-poll) that has information on preferences for moving broken down by age group. 

Read in the dataset, which is called `cal_housing.csv` in the data folder. 

```{r, message = F, warning = F}
cal_housing <- read_csv(here("data/cal_housing.csv"))
glimpse(cal_housing)
```

Our end goal is to make a visualization showing consideration of moving by age group. `ggplot2` presumes that we have tidy data to work. In order to make our graph, we need to *pivot* the non-variable columns into a two-column key-value pair. 

Recall from part 1 that the appropriate tidyverse function for this operation is `pivot_longer()`. 

```{r}
cal_housing_long <- cal_housing %>% 
  pivot_longer(-leaving, 
               names_to = "age", 
               values_to = "percent_agreement")
head(cal_housing_long)
```

From here, we could make a bar graph showing response by age groups. 
```{r}
cal_housing_long %>% 
  ggplot(aes(x = leaving, y = percent_agreement, fill=age))+
  geom_col(position = 'dodge')+
  xlab("Moving Consideration Level")+
  ylab("Percent Agreement")+
  # colorblind friendly palette
  scale_fill_discrete(type = "viridis")+
  ggtitle("Californians Consideration to Leaving the State")

```

## Challenge 9 

The IGS poll also contains a question broken down by region (`cal_region.csv`). Build a pipeline that reads and tidies the data. For extra practice, make a similar graph to display the results. 

```{r}
## Fill in your solution here 
```

## Overloading variables into a single column. 

Sometimes we have a dataset where our key column is a combination of multiple variables. To my knowledge, this is a rather common raw data format in research projects that collect data at multiple sub-level sites over time. 

To illustrate the problem, consider the following dataset inspired by bird watchers. 

```{r}
birds <- read_csv(here("data/birds.csv"))
glimpse(birds)
```

We see that we have columns that combine two different variables, the species of bird, and the location of a sighting. When encountering this situation, we use a two step process. 

1. Pivot to gather the non-variable columns 
2. Separate the overloaded column. 

In a workflow, it looks like this 

```{r}
goodBirds <- birds %>% 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE)%>%
  separate(sight, c("type", "location"),sep = "(?=[A-Z])")
glimpse(goodBirds)
```

The workflow above used a [regular expression](https://stringr.tidyverse.org/articles/regular-expressions.html) to split and keep the capital letter. Regular expressions are in general beyond the scope of this course. 

Another way to separate is by position. That call looks like this 

```{r, eval = F}
separate(col = VAR, into = c("VAR1", "VAR2"), sep = NUMBER)
## example that splits on the first character 
separate(col = col, into = c("var1", "var2"), sep = 1)
```

On datasets that have a standard format, separating by position can be useful. Let's look at what happens when we separate by the 1st position 

```{r}
sepEx <- birds %>% 
  pivot_longer(!c(county,year), 
               names_to = "sight",
               values_to = "n",
               values_drop_na = TRUE)%>%
  separate(sight, c("type", "location"),sep = 1)
glimpse(sepEx)
```

We can fix our incorrect columns with `mutate()`. The following is a brute force method to do this, but as you continue on in your data wrangling journey I strongly encourage you to seek out more efficient ways of solving this problem. 

```{r}
sepExFixed <- sepEx %>% 
  mutate(type = if_else(type == "e", "Eagle", "Warbler"),
         location = case_when(
           location == "agleNest"~"Nest",
           location == "agleAir"~"Air",
           location == "arblerNest"~"Nest",
           location == "arblerAir"~"Air"
         ))
head(sepExFixed)
```


## Challenge 10 

Edit the workflow presented above to split on the fifth character. Use `mutate` to replace the incorrect values with corrected and capitalized names. You can follow the brute force way shown above, or potentially investigate [str_replace_all()](https://stringr.tidyverse.org/reference/str_replace.html), [str_detect()](https://stringr.tidyverse.org/reference/str_detect.html), and [str_to_title()](https://stringr.tidyverse.org/reference/case.html) for options with string matching. 

```{r}


```


## Storing variables in both rows and columns. 

Far less often, though far more frustratingly, variables can be stored in both rows and columns. Such datasets occur with surprising frequency in climate, geological, and health research. As a representative example of this problem, consider the hypothetical surveillance testing schedule for an athlete at Berkeley during the season. The data is called `testing.csv`

```{r}
testing <- read_csv(here("data/testing.csv"))
head(testing)
```

Note that we have variables in individual columns, as well as a variable spread across multiple columns (the day variable), and variables spread across rows (the test variable is composed of two separate tests). 

In such a situation, we make use of both `pivot_longer()` and `pivot_wider()`. Our design pattern is to first gather any variables spread across columns, followed by widening any columns that have multiple variables within. 

```{r}
## Step 1 
step_1 <- testing %>% 
  pivot_longer(
    # an alternative method for selecting columns
    d1:d7, 
    names_to = "day",
    values_to = "result",
    values_drop_na = TRUE
  )%>%
  # remove the d from day and trim any white space
  # VERY USEFUL to avoid merge problems
  mutate(day = as.numeric(str_replace_all(day,"d", ""))%>%trimws())
head(step_1)
```

We now have a dataset that is close to a tidy dataset, except we have a problem. There are two tests being performed each day, and we only have one variable. Time for step 2. 

```{r}
step_2 <- step_1 %>% 
  pivot_wider(
    names_from = test, 
    values_from = result
  )
glimpse(step_2)
```

Now we have one variable in each column, and each row represents a single day of testing. 

## Storing multiple types of units in the same data frame. 

A key principle of tidy data, and data wrangling in general, is to keep like for like in the same table. Datasets often violate this guideline when they have values collected at multiple levels on different types of observations. 

### Two Table Verbs

### joins 

### Bind_cols/Bind_rows 

#### `bind_cols()` combines variables 

#### `bind_rows()` combines cases 

## Storing a single unit in multiple tables. 


